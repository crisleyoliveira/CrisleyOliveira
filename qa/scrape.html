// Function to save the scraped data to a file
function saveToFile(data, fileName) {
  const blob = new Blob([data], { type: 'text/plain;charset=utf-8' });
  const anchor = document.createElement('a');
  anchor.href = URL.createObjectURL(blob);
  anchor.download = fileName;
  anchor.click();
}

// Function to scrape the content
function scrapeContent() {
  // Select the elements with the specified classes
  const elements = document.querySelectorAll('.ggiVUv .gxburh, .ggiVUv .dOINxy, .ggiVUv .iEPiQX, .ggiVUv .fIxulM:first-of-type .jVGbYV, .ggiVUv .fIxulM:last-of-type .jVGbYV, .ggiVUv .hsWciN, .ggiVUv .fldhKw');

  // Create an empty array to store the scraped content
  const scrapedData = [];

  // Loop through each selected element and extract the text content
  elements.forEach((element) => {
    const content = element.textContent.trim();
    scrapedData.push(content);
  });

  // Convert the scraped data to a string
  const dataString = scrapedData.join('\n');

  // Save the file
  saveToFile(dataString, 'scraped_data.txt');
}

// Fetch the HTML content of the static page
fetch('https://crisleyoliveira.com/qa/index.html')
  .then((response) => response.text())
  .then((htmlContent) => {
    // Parse the HTML content using DOMParser
    const parser = new DOMParser();
    const doc = parser.parseFromString(htmlContent, 'text/html');

    // Set the document to the fetched HTML content
    document.documentElement.replaceWith(doc.documentElement);

    // Call the scrapeContent function to perform scraping and save the file
    scrapeContent();
  })
  .catch((error) => {
    console.error('Error fetching or parsing the HTML:', error);
  });
